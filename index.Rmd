---
title: "K-Pop vs Western Pop"
author: "Shankar Rai"
date: "`r Sys.Date()`"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(flexdashboard)
library(tidyverse)
library(spotifyr)
library(ggplot2)
library(plotly)
library(compmus)
library(tidymodels)
library(modeldata)
library(recipes)
library(heatmaply)
library(ggdendro)

westernPop <- get_playlist_audio_features("", "3lro0N5fTyoXFZFbowlcdM")
westernPop <- westernPop[!is.na(westernPop$tempo), ][1:100,] %>%
  add_audio_analysis()
koreanPop <- get_playlist_audio_features("", "30EtqO7XgA36lwcdj1Uuex") %>%
  add_audio_analysis()
allPop <- 
  koreanPop %>%
  mutate(genre = "Korean Pop") %>%
  bind_rows(westernPop %>% mutate(genre="Western Pop"))
```

### Classifying between the two genres
```{r, echo=FALSE}
features <-
  allPop %>%
  mutate(
    genre = factor(genre),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

pop_recipe <-
  recipe(
    genre ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = features,          # Use the same name as the previous block.
  )

pop_cv <- features %>% vfold_cv(5)

forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
pop_forest <- 
  workflow() %>% 
  add_recipe(pop_recipe) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    pop_cv, 
    control = control_resamples(save_pred = TRUE)
  )
pop_forest %>% get_pr()

workflow() %>% 
  add_recipe(pop_recipe) %>% 
  add_model(forest_model) %>% 
  fit(features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")

plot_diff <- features %>%
  ggplot(aes(x = loudness, y = c01, colour = genre, size = duration)) +
  geom_point(alpha = 0.8) +
  scale_color_viridis_d() +
  labs(
    x = "Timbre Component 1",
    y = "Loudness",
    size = "Duration",
    colour = "Genre"
  )

ggplotly(plot_diff)
```

***
These visualizations indicate the differences between the two genres and on what features a Random Forest Classifier based its classifications. The precision and recall of the classifier are pretty good and according to the workflow this is mostly due to the first timbre component, loudness and duration of the songs. Visualizing these features in a graph makes it visible that these features indeed form a pretty good identifier for these genres. There is a decent possible separation line between the two genres based on these three alone. This would explain the good precision and recall as well. Note: The legend of the plot is not that nice as there is a problem with the conversion from the ggplot to ggplotly, trying to figure this out. The size of the dots indicate the duration of the song.


### Comparison of lower-track features
```{r, echo=FALSE}
allPop %>%
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) %>%
  unnest(sections) %>%
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

***
This plot visualizes the mean tempo of the songs in the two different playlist and their standard deviations. As is visible a lot of the songs from both playlists are fairly similar range in their tempo and their standard deviations. This seems to be quite logical as pop music is forged from music that is appealing to most people. So they keep around the same foundation. What is also visible from the plot is that the duration of most of the songs is also similar, around 3 - 3.5. There are however some differences visible in the volume of the songs.

### Self similartity
```{r, echo=FALSE}
dc <-
  get_tidy_audio_analysis("3L74uwShK0JqEUZ5Y2JoDW") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

timbreDF <- dc %>% compmus_self_similarity(timbre, "cosine")
timbreDF$name <- "Timbre"
pitchesDF <- dc %>% compmus_self_similarity(pitches, "cosine")
pitchesDF$name <- "Chroma"
together <- rbind(pitchesDF, timbreDF)

together %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "") +
  facet_wrap(~name)

```

***
Looking at the chromatic and timbre graphs of the Korean song BEcause from the group Dreamcatcher, you can see some similarities between around 150 and higher.


### Introduction

Repository for Computational Musicology 2022.\
Name: Shankar Rai, Student number: 12520667. \
PLEASE DO NOT SHOW THIS PORTFOLIO IN CLASS.

For the corpus the 100 most popular western pop music of 2010 - 2020 and the 100 most popular Korean pop (K-pop) music of the recent years will be used. I chose those as I am interested in both of these genres and I listen to them a lot. Therefore I am interested in the similarities and differences between sounds in these genres as K-pop is becoming more and more popular in western countries. I expect there to be differences in the tempo, energy and danceability.

As the corpus makes use of the top 100, of both genres in recent years I would argue that they represent both genres pretty well. One of the weaknesses of the corpus are that it makes use of a list not created by spotify itself. Therefore it may not be an absolute top 100. Another weakness may be that the western list is not only English based, but may also contain Latin influences. One extra thing to mark is that some K-pop songs are collaborations with western artist.

Some typical track from the western list are: "Shape of You, Ed Sheeran", "Sugar, Maroon 5", "Can't feel my face, The Weeknd". Some typical K-pop tracks are "Dynamite, BTS", "I cant"t stop me, Twice", "Kill This Love, BLACKPINK". These are typical songs as these are from some of the biggest artist in their respective genres. Some interesting songs are: "More, KD/A" and "Kiss and Make Up, "Dua Lipa, BLACKPINK" as these are collaborated songs with Korean and western artists.

Links to the playlists:\
[Western pop]("https://open.spotify.com/playlist/3lro0N5fTyoXFZFbowlcdM")\
[Korean pop]("https://open.spotify.com/playlist/30EtqO7XgA36lwcdj1Uuex")

### Energy level comparison

```{r, echo=FALSE}
energy <- ggplot(allPop, aes(x=energy)) +
  geom_histogram(bins=10) +
  theme_minimal() +
  labs(
    x = "Energy Level",
    y = "Amount of songs",
    title = "Korean songs seem to have higher energy songs",
    subtitle = "Comparison of the energy in songs between the two playlists"
  ) +
  facet_wrap(~genre)

ggplotly(energy)

```

***

When looking at the differences between the energy levels of western pop songs and Korean pop songs you can certainly see a difference.

As is visible in the histogram the mean of the energy of western pop songs is around 0.7, while most of the Korean pop songs have an energy level higher than that. The K-pop songs have a mean energy around 0.85. This shows that K-pop songs have higher energy levels than most of the western songs.

### Chromatic Features of outlier

```{r, echo=FALSE}
more <-
  get_tidy_audio_analysis("6juLaduD4STCUDWT0AYun4") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

more %>%
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title="Chroma features MORE K/DA") +
  theme_minimal() +
  scale_fill_viridis_c()

```

***

MORE from K/DA is an interesting song as the group K/DA is a virtual group with their real life counterparts being Korean and Western artists. So the songs is made as a collaboration of western and Korean artist and therefore it would be interesting if its possible to see how their styles combine in the music. As is visible in the charts the played notes are definitely pretty consistent. This seems to be more of a western style as it is more common in Korean music to have a lot of switches in the notes. Therefore while it is categorized as K-pop and it is sung by Korean artist the notes and cords still have a Western feel.

